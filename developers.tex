\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{csquotes}
\usepackage{makeidx}
\makeindex

\title{Compiler Documentation}
\author{Thomas Maloney \\ 
net-id: \href{mailto:tmaloney@iastate.edu}{tmaloney@iastate.edu}}
\date{April 2021}

\begin{document}

\maketitle

\tableofcontents
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}

\newpage
\section{Overview}
The compiler has been rewritten in C++ and has gone through a complete "makeover" so to speak.
The documentation on the old C code from previous versions is in the document \code{developers-old.pdf} which is very much outdated and exists purely for historical reasons.
The documentation is now broken up into a section for each namespace in the source code to give an overview of the purpose of each module and the data structures used.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                            %
%                DEFAULT                     %
%                                            %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The Default Namespace}
\label{default:namespace}

\subsection{main.cpp}
\label{default:main}
This file contains the entry point of the compiler.
It passes the arguments from the command line to a method that parses them (described in section \ref{defautl:argparser}) and returns a \code{struct} that contains info about what flags were passed and what the possible output file might be (should that have been given).
I then check which flag got passed in and whether the output should be written to a provided file or just \code{stdout}.
Contains helper methods to handle manually running the lexer, or running the parser and handling the list of translation unit syntax tree nodes (either to be ran through the syntax checker for part 2 or passed to the binder for parts 3+).

\subsection{arg\_parser}
\label{defautl:argparser}
This actually has not changed much, if at all from the original C variant, so to paraphrase what the C variant did:

\begin{displayquote}
    The header file contains a \code{struct}, an \code{enum}, and a method signature that gets implemented in \code{args\_parser.c}.
    Here I use \code{getopt} from \code{unistd.h} to read/parse each flag and then record which flag and whether there was an output file to a \code{struct} that I return.
    The potential output file gets passed back as an out-parameter.
    If no flags were passed in, or one that doesn't exist, I print out the string that describes how to use the program to \code{stderr}.
\end{displayquote}

\subsection{driver}
\label{default:driver}
The \code{driver} class was written so that flex and bison can "communicate" and also gives me a single interface with which I can interact with the lexer and parser.
The C++ documentation for bison was pretty underwhelming (at least for use cases where you wanted to treat the parser like you were using C++ and not just trying to interface with C)
and the C++ documentation for flex was almost nonexistant so the \code{driver} class is the result of what I \emph{think} is necessary for them to pass data between eachother in C++ land.

As for custom data I store in the driver, I keep a list of \code{TranslationUnitNode}s that get synthesized by the parser after it finishes its rounds so to speak.
There's more on that in section \ref{syntax:namespace}.
I also keep track of the current file (although multifile code support is effectively dropped in part 3 onward, still technically works in parts 1 and 2 though).
I also keep track of a list of \code{LexemeDataNode}s (see section \ref{default:lexemes} below) and a flag to indicate if any errors occured.

\subsection{lexeme\_data.h}
\label{default:lexemes}
This defines a class \code{LexemeDataNode} which contains token information generated by the lexer.
The purpose of this class is to allow me to collect the token data neccessary for output in part 1 without having to print the data immediately to the console.
Ultimately, the reason why I didn't just build a list of strings instead was so I could fix any output formatting issues in one spot instead of having to \code{grep} through the lexer.l file.

\subsection{lexer}
\label{default:lexer}
The biggest change that was made to the lexer from the previous version is that it now interacts with the \code{driver} class and passes all tokens through to bison as a \code{SyntaxToken} data type.
More on that in section \ref{syntax:namespace}.
Other than that, it still just handles the parsing of lexemes.

\subsection{mycc.ypp}
\label{default:parser}
The bison grammar file, imports almost all (if not actually all) syntax node classes from the \code{Syntax} namespace described in section \ref{syntax:namespace}.

\subsection{part\_two\_syntax\_check}
\label{default:syntaxcheck}
The \code{PartTwoSyntaxPrinter} class takes in the root node of the syntax tree keeping a (slightly less crude than before) "symbol" table of the variables, structs, and functions (along with their params, and local structs and variables).
It then calls the instance of the \code{Logger} it gets passed and prints out the syntax information of the file that it parsed.

\subsection{qsem}
\label{default:qsem}
The "Quick Semantic Analyzer".
It's quick since it actually isn't doing any analysis, rather it's just the code that logs the results from the analysis (which is actually done by the \code{binder} as described in section \ref{binding:namespace}).
Also technically in its own namespace since originally when I was porting to C++, \code{qsem} was going to actually perform some half-backed semantic analysis just as a sanity check while I was working on the binding code. 

\subsection{syntax\_tree\_printer}
\label{default:syntaxtreeprinter}
This is just an addition I made to help me debug parsing and to some degree binding as well, it can be invoked like \code{./mycc -6 [input file]}.
Note that it only prints to standard out.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                            %
%                LOGGING                     %
%                                            %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The Logging Namespace}
\label{logging:namespace}

\subsection{logger}
\label{logging:logger}
A generic logging class that takes in an output stream on construction so to direct the output of the log calls.

\subsection{diagnostics}
\label{logging:diagnostics}
A class that essentially acts as a wrapper around a list of strings.
The interface for this class is just a list of functions that report semantic errors to a private vector of strings.
This way, if I want/need to change the message that gets reported, I just need to change a string in one method as opposed to searching for it throughout the codebase.

\subsection{part\_three\_info}
\label{logging:seminfo}
Contains the structs: \code{PartThreeVariableInfo}, \code{PartThreeStructInfo}, \code{PartThreeStatementInfo}, \code{PartThreeFunctionInfo}, and \code{PartThreeInfoList}.
These essentially act as the "part 3" equivalent of the \code{PartTwoSyntaxPrinter} class (see section \ref{default:syntaxcheck}).
The biggest difference in this case (other than the fact that the structs above contain info about the bound tree and the class from section \ref{default:syntaxcheck} deals with the syntax tree) is that the part three info structs are built during binding, instead of while traversing the bound tree afterwards.
This is done since I don't attach \code{SyntaxToken} information to every \code{BoundNode} like I do with every \code{SyntaxNode}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                            %
%                SYMBOLS                     %
%                                            %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The Symbols Namespace}
\label{symbols:namespace}

\subsection{symbol}
\label{symbol:symbol}
Abstract class that resembles some symbol type that would be stored in a symbol table.
Contains a protected field to store the name of the symbol (e.g. a function name, type name, variable name, etc.) and an abstract method for getting what kind of symbol it is.

\subsection{parameter\_symbol}
\label{symbol:parametersymbol}
Represents a parameter to a function.
Contains a \code{TypeSymbol} (see section \ref{symbol:typesymbol}) instance that records what C type the parameter is (e.g. int, const float, char[], struct somedata, etc).
Also records whether the parameter is a constant and if it is an array type.

\subsection{function\_symbol}
\label{symbol:functionsymbol}
Represents a function in code.
Like the \code{ParameterSymbol}, this also contains a \code{TypeSymbol} instance to keep track of the type of value the function returns.
It also contains a list of \code{ParameterSymbol}s that keep track of the function's parameter info.
Since there can exist multiple function prototypes for a single function, I keep track of the line that the function is defined on so when looking defining the function, I can check whether it already has been defined or if it was just declared.

\subsection{type\_symbol}
\label{symbol:typesymbol}
The \code{TypeSymbol} class sort of ended up as the "mac daddy" of the other symbol types.
It contains an instance of a struct \code{TypeAttribute}s which keep track of whether the type is a struct, an integer type, a numeric type, an array, and/or a constant.
The \code{TypeAttribute}s struct has a partial ordering (\code{std::partial\_ordering} in C++20) defined on it that says for any two given \code{TypeAttributes} $\alpha_0$ and $\alpha_1$, we have
\begin{equation*}
    \Leftrightarrow (\alpha_0,\alpha_1) = 
    \begin{cases}
        \text{undordered} & \text{only one of $\alpha_0$ or $\alpha_1$ is either an array or a struct} \\
        \text{less} & \alpha_0\in\Z \text{ and } \alpha_1\in\R\setminus\Z \\
        \text{greater} & \alpha_1\in\Z \text{ and } \alpha_0\in\R\setminus\Z \\
        \text{equivalent} & \text{all of $\alpha_0$ and $\alpha_1$ attributes are equal} \\
        \text{unordered} & \text{otherwise}
    \end{cases}
\end{equation*}

(I know technically $x\in\R\setminus\Z$ isn't the best (or even remotely accurate) way to represent $x$ is a \code{float} and not an \code{int}, but I felt it still gets the message across).
(Also, the reason for choosing the symbol $\Leftrightarrow$ is because C++20's three way comparitor is written \code{<=>} which in my case returns the partial order).
I then defined a partial order on the \code{TypeSymbol} class itself that says for any two \code{TypeSymbol}s $\tau_0$ and $\tau_1$, we have
\begin{equation*}
    \Leftrightarrow (\tau_0, \tau_1) =
    \begin{cases}
        \alpha(\tau_0) \Leftrightarrow \alpha(\tau_1) & \alpha(\tau_0) \Leftrightarrow \alpha(\tau_1) \text{ does not evaluate as equivalent} \\
        \text{id}(\tau_0) \Leftrightarrow \text{id}(\tau_1) & \text{otherwise}
    \end{cases}
\end{equation*}
Where $\alpha(\tau)$ represents the \code{TypeAttribute}s of some type $\tau$ and id$(\tau)$ returns the name of some type $\tau$.

This partial order can be intuited as representing whether a given type can be "widened" to another given type.
For example, $\Leftrightarrow (\text{char}, \text{float}) = \text{Less}$ which means that \code{char} can be widened to a \code{float}.
Types that are "unordered" are unable to be cast to eachother, both implicitly and explicitly.

One of the convinient parts about this is that it makes it relatively easy to determine the wider type of two types in a binary expression (which also makes it easy to determine if the operator is valid on two types).

\subsection{struct\_symbol}
\label{symbol:structsymbol}
The \code{StructSymbol} class represents information about a user defined struct.
It contains a list of \code{VariableSymbol}s which are used to keep track of the type information about the struct's members.

\subsection{variable\_symbol}
\label{symbol:variablesymbol}
The \code{VariableSymbol} class represents information about a variable, be it global or local (or in the case described in section \ref{symbol:structsymbol}, represents members of a user defined type).
It contains information the type of the variable, whether or not it is an array type (and if so, what its size is), and whether or not it is a constant.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                            %
%                SYNTAX                      %
%                                            %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The Syntax Namespace}
\label{syntax:namespace}

\subsection{Overview}
\label{syntax:overview}

\subsection{Syntax Expressions}
\label{syntax:expressions}

\subsection{Syntax Statements}
\label{syntax:statements}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                            %
%                BINDING                     %
%                                            %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The Binding Namespace}
\label{binding:namespace}

\subsection{Overview}
\label{binding:overview}

\subsection{Bound Expressions}
\label{binding:expressions}

\subsection{Bound Statements}
\label{binding:statements}

\end{document}